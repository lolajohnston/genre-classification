{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect_langs\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "import plotly.graph_objects as go\n",
    "# from better_profanity import profanity\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "veclyrics = np.load('veclyrics.pkl',allow_pickle = True)\n",
    "df = pd.read_pickle(\"response.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(veclyrics, df['pop'], test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge #import ridge \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test) # make predictions for X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.617739096420888\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial Naive Bayes Accuracy:', accuracy_score(y_test, y_pred)) # accuracy of predictions\n",
    "\n",
    "#metrics.accuracy_score(y_test, y_pred) same output as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59315926, 0.40684074],\n",
       "       [0.53024762, 0.46975238],\n",
       "       [0.59985787, 0.40014213],\n",
       "       ...,\n",
       "       [0.58576483, 0.41423517],\n",
       "       [0.62871555, 0.37128445],\n",
       "       [0.6364539 , 0.3635461 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict_proba(X_test) # checking the probability of accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5617\n",
      "1    4609\n",
      "Name: pop, dtype: int64\n",
      "Null accuracy: 0    0.549286\n",
      "Name: pop, dtype: float64\n",
      "Manual null accuracy: 0.5492861333854879\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())\n",
    "# there is a majority class of 0 here, hence the classes are skewed\n",
    "\n",
    "# calculate null accuracy (for multi-class classification problems)\n",
    "# .head(1) assesses the value 1208\n",
    "null_accuracy = y_test.value_counts().head(1) / len(y_test)\n",
    "print('Null accuracy:', null_accuracy)\n",
    "\n",
    "# Manual calculation of null accuracy by always predicting the majority class\n",
    "print('Manual null accuracy:',(5617 / (5617 + 4609)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40684074, 0.46975238, 0.40014213, ..., 0.41423517, 0.37128445,\n",
       "       0.3635461 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "\n",
    "# Numpy Array with 2C\n",
    "# left Column: probability class 0\n",
    "# right C: probability class 1\n",
    "# we only need the right column \n",
    "y_pred_prob = nb.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob\n",
    "\n",
    "# Naive Bayes predicts very extreme probabilites, you should not take them at face value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68786596248958"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AUC is useful as a single number summary of classifier performance\n",
    "\n",
    "* Higher value = better classifier\n",
    "\n",
    "* If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation\n",
    "\n",
    "* AUC is useful even when there is high class imbalance (unlike classification accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = BernoulliNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb_y_pred = gnb.predict(X_test)\n",
    "accuracyBNB = gnb.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for bernoulli naive bayes: 0.6408175239585371\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for bernoulli naive bayes:\", accuracyBNB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4008, 1609],\n",
       "       [2064, 2545]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, gnb_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7718260274307508"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RidgeClassifier().fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Randomized Search for Algorithm Tuning\\nimport numpy as np\\nfrom scipy.stats import uniform as sp_rand\\nfrom sklearn import datasets\\nfrom sklearn.linear_model import Ridge\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# load the diabetes datasets\\ndataset = df\\n# prepare a uniform distribution to sample for the alpha parameter\\nparam_grid = {'alpha': sp_rand()}\\n# create and fit a ridge regression model, testing random alpha values\\nmodel = Ridge()\\nrsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\\nrsearch.fit(df., dataset.target)\\nprint(rsearch)\\n# summarize the results of the random parameter search\\nprint(rsearch.best_score_)\\nprint(rsearch.best_estimator_.alpha)\\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "# need help with this part\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# load the diabetes datasets\n",
    "dataset = df\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(df., dataset.target)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors\n",
    " * reference: https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import StandardScaler\\nscaler = StandardScaler()\\nscaler.fit(X_train)\\n\\nX_train = scaler.transform(X_train)\\nX_test = scaler.transform(X_test)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3118 2499]\n",
      " [2108 2501]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58      5617\n",
      "           1       0.50      0.54      0.52      4609\n",
      "\n",
      "    accuracy                           0.55     10226\n",
      "   macro avg       0.55      0.55      0.55     10226\n",
      "weighted avg       0.55      0.55      0.55     10226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Error Rate with the K Value\n",
    "\n",
    "* There is no way to know beforehand which value of K that yields the best results in the first go. So randomly choose 5 as the K value.\n",
    "\n",
    "* One way to find the best value of K is to plot the graph of K value and the corresponding error rate for the dataset.\n",
    "\n",
    "* Below, is a plot of the mean error for the predicted values of test set for all the K values between 1 and 40.\n",
    "\n",
    "* To do this, we had to first calculate the mean of error for all the predicted values where K ranges from 1 and 40. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script executes a loop from 1 to 40. In each iteration the mean error for predicted values of test set is calculated and the result is appended to the error list.\n",
    "\n",
    "The next step is to plot the error values against K values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lolajohnston/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/lolajohnston/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import nltk\n",
    "import sklearn\n",
    "import nltk.collocations \n",
    "from nltk import FreqDist, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string, re\n",
    "import urllib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#import xgboost as xgb\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('clf',\n",
      "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
      "         verbose=False)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('clf',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=None,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators='warn', n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('clf',\n",
      "                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "                                    learning_rate=0.3, n_estimators=50,\n",
      "                                    random_state=None))],\n",
      "         verbose=False)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('clf',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=5, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Multinomail NB pipeline test accuracy: 0.618\n",
      "Random Forest pipeline test accuracy: 0.588\n",
      "ADA pipeline test accuracy: 0.613\n",
      "KNN pipeline test accuracy: 0.549\n"
     ]
    }
   ],
   "source": [
    "pipe_NB = Pipeline([('clf', MultinomialNB())\n",
    "                    ])\n",
    "\n",
    "pipe_RF = Pipeline([('clf', RandomForestClassifier())\n",
    "                    ])\n",
    "\n",
    "pipe_ADA = Pipeline([('clf', AdaBoostClassifier(learning_rate=0.3))\n",
    "                    ])\n",
    "\n",
    "\n",
    "pipe_KNN = Pipeline([('clf', KNeighborsClassifier())\n",
    "                    ])\n",
    "\n",
    "# List of pipelines, List of pipeline names\n",
    "pipelines = [pipe_NB, pipe_RF, pipe_ADA, pipe_KNN]\n",
    "pipeline_names = ['Multinomail NB', 'Random Forest', 'ADA', \"KNN\"]\n",
    "\n",
    "# Loop to fit each of the three pipelines\n",
    "for pipe in pipelines:\n",
    "    print(pipe)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare accuracies\n",
    "basic_scores = []\n",
    "for index, val in enumerate(pipelines):\n",
    "    tup = (pipeline_names[index], val.score(X_test, y_test))\n",
    "    basic_scores.append(tup)\n",
    "    print('%s pipeline test accuracy: %.3f' % (pipeline_names[index], val.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tabled methods\n",
    "\n",
    "\n",
    "#### OneVsRest - problem transformation method\n",
    "\n",
    "#### treats the problem like multiple sets of binary classification problems\n",
    "\n",
    "* Traditional two-class and multi-class problems can both be cast into multi-label ones by restricting each instance to have only one label. On the other hand, the generality of multi-label problems inevitably makes it more difficult to learn. An intuitive approach to solving multi-label problem is to decompose it into multiple independent binary classification problems (one per category).\n",
    "\n",
    "* In an “one-to-rest” strategy, one could build multiple independent classifiers and, for an unseen instance, choose the class for which the confidence is maximized.\n",
    "\n",
    "* The main assumption here is that the labels are mutually exclusive. You do not consider any underlying correlation between the classes in this method.\n",
    "\n",
    "* For instance, it is more like asking simple questions, say, “is the comment toxic or not”, “is the comment threatening or not?”, etc. Also there might be an extensive case of overfitting here, since most of the comments are unlabeled, i,e., most of the comments are clean comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs rest \n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "#LogReg_pipeline = Pipeline([\n",
    "                #('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
